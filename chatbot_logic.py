"""
ì²­ì†Œë…„ ì¸ì§€ ì¬êµ¬ì¡°í™” ì±—ë´‡ - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (GPT API ì—°ë™)
"""

import streamlit as st
from openai import OpenAI
import datetime
import os
import json

# ========== ì•ˆì „ ì—ì´ì „íŠ¸ Import ==========
try:
    from safety_agent_simplified import (
        SafetyAgent,
        display_safety_alert,
        display_emergency_screen,
        log_safety_assessment
    )
    SAFETY_AGENT_AVAILABLE = True
except ImportError:
    SAFETY_AGENT_AVAILABLE = False
    print("âš ï¸ ì•ˆì „ ì—ì´ì „íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# ========== API í‚¤ í—¬í¼ í•¨ìˆ˜ ==========
def get_api_key():
    """
    API í‚¤ ê°€ì ¸ì˜¤ê¸° (Streamlit Secrets ìš°ì„ , í™˜ê²½ë³€ìˆ˜ ëŒ€ì²´)
    """
    try:
        # Streamlit Secrets ì‹œë„
        api_key = st.secrets.get("OPENAI_API_KEY")
        if api_key:
            return api_key
    except:
        pass
    
    # í™˜ê²½ë³€ìˆ˜ ì‹œë„
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return api_key
    
    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì—ëŸ¬
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Secretsì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    return None



def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'user_info_collected' not in st.session_state:
        st.session_state.user_info_collected = False
    if 'user_info' not in st.session_state:
        st.session_state.user_info = {}
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    if 'current_stage' not in st.session_state:
        st.session_state.current_stage = 'collection'  # collection, analysis (Stage 3ëŠ” ì¶”í›„ êµ¬í˜„)
    if 'analysis_data' not in st.session_state:
        st.session_state.analysis_data = None
    if 'distortion_extracted' not in st.session_state:
        st.session_state.distortion_extracted = False  # ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì™„ë£Œ ì—¬ë¶€
    if 'awaiting_distortion_selection' not in st.session_state:
        st.session_state.awaiting_distortion_selection = False  # ì™œê³¡ ì„ íƒ ëŒ€ê¸° ì—¬ë¶€
    if 'selected_distortion' not in st.session_state:
        st.session_state.selected_distortion = None  # ì„ íƒëœ ì™œê³¡
    if 'awaiting_restructuring_start' not in st.session_state:
        st.session_state.awaiting_restructuring_start = False  # ì¬êµ¬ì¡°í™” ì‹œì‘ ëŒ€ê¸°
    if 'restructuring_method' not in st.session_state:
        st.session_state.restructuring_method = None  # ì„ íƒëœ ì¬êµ¬ì¡°í™” ë°©ë²•
    if 'evaluation_logs' not in st.session_state:
        st.session_state.evaluation_logs = []  # í‰ê°€ ë¡œê·¸ ì €ì¥
    
    # ========== ë¹ ë¥¸ ë‹µë³€ ì„ íƒì§€ ==========
    if 'quick_replies' not in st.session_state:
        st.session_state.quick_replies = None  # í˜„ì¬ ì„ íƒ ê°€ëŠ¥í•œ ë‹µë³€ë“¤
    
    # ========== ì•ˆì „ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ==========
    if 'safety_agent' not in st.session_state and SAFETY_AGENT_AVAILABLE:
        print("\n[ì•ˆì „ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹œì‘]")
        try:
            # API í‚¤ (ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ ë™ì¼)
            api_key = get_api_key()
            
            if api_key:
                st.session_state.safety_agent = SafetyAgent(api_key)
                print("âœ… ì•ˆì „ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì„±ê³µ!")
            else:
                st.session_state.safety_agent = None
                print("âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        except Exception as e:
            st.session_state.safety_agent = None
            print(f"âŒ ì•ˆì „ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    elif not SAFETY_AGENT_AVAILABLE:
        print("âŒ SAFETY_AGENT_AVAILABLE = False (Import ì‹¤íŒ¨)")
    elif 'safety_agent' in st.session_state:
        print(f"âœ… ì•ˆì „ ì—ì´ì „íŠ¸ ì´ë¯¸ ì´ˆê¸°í™”ë¨ (None: {st.session_state.safety_agent is None})")
    
    if 'emergency_mode' not in st.session_state:
        st.session_state.emergency_mode = False
    
    if 'last_risk_level' not in st.session_state:
        st.session_state.last_risk_level = 1


def add_evaluation_log(log_type, data):
    """í‰ê°€ ë¡œê·¸ ì¶”ê°€"""
    if 'evaluation_logs' not in st.session_state:
        st.session_state.evaluation_logs = []
    
    import datetime
    log_entry = {
        'timestamp': datetime.datetime.now().isoformat(),
        'type': log_type,
        'data': data
    }
    st.session_state.evaluation_logs.append(log_entry)


def save_user_info(user_info):
    """ì‚¬ìš©ì ì •ë³´ ì €ì¥"""
    st.session_state.user_info = user_info
    st.session_state.user_info_collected = True


def reset_session():
    """ì„¸ì…˜ ì´ˆê¸°í™” (ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°)"""
    st.session_state.user_info_collected = False
    st.session_state.messages = []
    st.session_state.conversation_history = []
    st.session_state.current_stage = 'collection'


def export_conversation_to_json():
    """ëŒ€í™” ë‚´ìš©ì„ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    import json
    import datetime
    
    # Stageë³„ë¡œ ë©”ì‹œì§€ ë¶„ë¥˜
    stage_messages = {
        'collection': [],
        'analysis': [],
        'restructuring': []
    }
    
    for msg in st.session_state.messages:
        stage = msg.get('stage', 'collection')
        stage_messages[stage].append({
            'role': msg['role'],
            'content': msg['content'],
            'timestamp': msg.get('timestamp', '')
        })
    
    # ì „ì²´ ë°ì´í„° êµ¬ì„±
    export_data = {
        'metadata': {
            'export_time': datetime.datetime.now().isoformat(),
            'user_info': st.session_state.get('user_info', {}),
            'current_stage': st.session_state.get('current_stage', 'collection')
        },
        'stages': {
            'stage1_collection': {
                'description': 'Stage 1: ê°ì •-ë…¼ë¦¬-í–‰ë™ ìˆ˜ì§‘',
                'turn_count': len([m for m in stage_messages['collection'] if m['role'] == 'user']),
                'messages': stage_messages['collection'],
                'analysis_result': st.session_state.get('analysis_data')
            },
            'stage2_analysis': {
                'description': 'Stage 2: ì¸ì§€ì™œê³¡ íƒìƒ‰',
                'turn_count': len([m for m in stage_messages['analysis'] if m['role'] == 'user']),
                'messages': stage_messages['analysis'],
                'distortion_data': st.session_state.get('distortion_data'),
                'selected_distortion': st.session_state.get('selected_distortion')
            },
            'stage3_restructuring': {
                'description': 'Stage 3: ì¸ì§€ ì¬êµ¬ì¡°í™”',
                'turn_count': len([m for m in stage_messages['restructuring'] if m['role'] == 'user']),
                'messages': stage_messages['restructuring'],
                'restructuring_method': st.session_state.get('restructuring_method')
            }
        },
        'evaluation_logs': st.session_state.get('evaluation_logs', []),
        'statistics': {
            'total_turns': len([m for m in st.session_state.messages if m['role'] == 'user']),
            'total_messages': len(st.session_state.messages),
            'stage1_turns': len([m for m in stage_messages['collection'] if m['role'] == 'user']),
            'stage2_turns': len([m for m in stage_messages['analysis'] if m['role'] == 'user']),
            'stage3_turns': len([m for m in stage_messages['restructuring'] if m['role'] == 'user'])
        }
    }
    
    return json.dumps(export_data, ensure_ascii=False, indent=2)


def get_emotion_message(intensity):
    """í•˜ë£¨ ì ìˆ˜ì— ë”°ë¥¸ ë©”ì‹œì§€ ë°˜í™˜"""
    if intensity <= 3:
        return "ìš”ì¦˜ ê´œì°®ì€ í¸ì´ì‹œêµ°ìš”. í•¨ê»˜ í¸ì•ˆí•˜ê²Œ ì´ì•¼ê¸° ë‚˜ëˆ ë´ìš”. ğŸ˜Š"
    elif intensity <= 6:
        return "ìš”ì¦˜ ë³´í†µ ì •ë„ì‹œêµ°ìš”. ì²œì²œíˆ í•¨ê»˜ ì‚´í´ë³¼ê²Œìš”. ğŸ¤—"
    else:
        return "ìš”ì¦˜ ë§ì´ í˜ë“œì‹œêµ°ìš”. ì¶©ë¶„íˆ ì´í•´í•©ë‹ˆë‹¤. í•¨ê»˜ ì°¨ê·¼ì°¨ê·¼ ì´ì•¼ê¸° ë‚˜ëˆ ë´ìš”. ğŸ’ª"


def get_welcome_message(user_info):
    """ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€ ìƒì„±"""
    return f"""ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš” ğŸŒŸ

{get_emotion_message(user_info['emotion_intensity'])}

ì˜¤ëŠ˜ì€ ì–´ë–¤ ìƒê°ì´ë‚˜ ê°ì •ì„ ì´ì•¼ê¸°í•˜ê³  ì‹¶ë‚˜ìš”? 
ë¬´ì—‡ì´ë“  í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”. í•¨ê»˜ ì²œì²œíˆ ìƒê°ì„ ì •ë¦¬í•´ë³¼ê²Œìš”.
"""


def load_prompt_from_file(file_path):
    """ì™¸ë¶€ íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        st.error(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return ""
    except Exception as e:
        st.error(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return ""


def get_persona_prompt():
    """í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° ì ìš©"""
    persona_id = st.session_state.get('selected_persona', 'friend')
    
    # í˜ë¥´ì†Œë‚˜ ì •ë³´
    PERSONAS = {
        "detective": {"name": "ë¶„ì„ì  ìˆëŠ” íƒì •í˜• (í˜•/ëˆ„ë‚˜)", "emoji": "ğŸ•µï¸"},
        "friend": {"name": "ë”°ëœ»í•œ ê°ì • ê³µê° ì¹œêµ¬í˜• (ì¹œêµ¬)", "emoji": "ğŸ’•"},
        "cool": {"name": "ì¿¨í•œ í˜•Â·ëˆ„ë‚˜í˜• (í˜„ì‹¤ì  ì¡°ë ¥ ìœ ë¨¸)", "emoji": "ğŸ˜"},
        "coach": {"name": "ìë¶„í•œ ê±´ë¬¸ ì½”ì¹˜í˜• (ìƒë‹´êµì‚¬ ëŠë‚Œ)", "emoji": "ğŸ§˜"}
    }
    
    # prompt9 íŒŒì¼ ë¡œë“œ
    try:
        prompt_file_path = "prompt9_persona.txt"
        with open(prompt_file_path, 'r', encoding='utf-8') as f:
            persona_prompt = f.read()
        
        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ì‚½ì…
        persona_info = PERSONAS.get(persona_id, PERSONAS['friend'])
        persona_prompt = persona_prompt.replace('{selected_persona}', persona_info['name'])
        
        return persona_prompt
    except FileNotFoundError:
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ ì„¤ëª…ë§Œ
        persona_info = PERSONAS.get(persona_id, PERSONAS['friend'])
        return f"\n\n**[ëŒ€í™” ìŠ¤íƒ€ì¼]**\nì„ íƒëœ í˜ë¥´ì†Œë‚˜: {persona_info['emoji']} {persona_info['name']}\nì´ í˜ë¥´ì†Œë‚˜ì˜ íŠ¹ì§•ì„ ì‚´ë ¤ ëŒ€í™”í•˜ì„¸ìš”.\n"
    except Exception as e:
        return ""


def get_system_prompt_stage1(user_info):
    """Stage 1: ì •ë³´ ìˆ˜ì§‘ ë‹¨ê³„ í”„ë¡¬í”„íŠ¸"""
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
    prompt_file_path = "prompt1.txt"
    
    # íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt1 = load_prompt_from_file(prompt_file_path)
    
    if not prompt1:
        # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt1 = """ë‹¹ì‹ ì€ ì²­ì†Œë…„ì˜ ê³ ë¯¼ì„ ê²½ì²­í•˜ë©° ì²´ê³„ì ìœ¼ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ì •ë³´ ìˆ˜ì§‘ í›„ [COLLECTION_COMPLETE] ì‹ í˜¸ë¥¼ ì¶œë ¥í•˜ì„¸ìš”."""
    
    # ì‚¬ìš©ì ì •ë³´ ì¶”ê°€
    user_context = f"""

**[ì‚¬ìš©ì ì •ë³´]**
- ì„±ë³„: {user_info['gender']}
- ë‚˜ì´: {user_info['age']}ì„¸
- í•˜ë£¨ ì ìˆ˜: {user_info['emotion_intensity']}/10 (0=ê´œì°®ìŒ, 10=ìµœì•…)

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ë˜, ëŒ€í™” ì¤‘ì—ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”."""

    # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    persona_prompt = get_persona_prompt()

    return prompt1 + user_context + persona_prompt


def get_system_prompt_stage2(user_info):
    """Stage 2: ì¸ì§€ì™œê³¡ íƒìƒ‰ ë‹¨ê³„ í”„ë¡¬í”„íŠ¸"""
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
    prompt_file_path = "prompt4.txt"
    
    # íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt4 = load_prompt_from_file(prompt_file_path)
    
    if not prompt4:
        # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt4 = """ë‹¹ì‹ ì€ ì²­ì†Œë…„ì˜ ì¸ì§€ì™œê³¡ì„ íƒìƒ‰í•˜ëŠ” ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ìë™ì  ì‚¬ê³ , ì¤‘ê°„ ì‹ ë…, í•µì‹¬ ì‹ ë…ì„ íƒìƒ‰í•˜ì„¸ìš”.
ì§ˆë¬¸ë³´ë‹¤ëŠ” ë°˜ì˜, ìš”ì•½, ê³µê°ì„ ë§ì´ ì‚¬ìš©í•˜ì„¸ìš”."""
    
    # ì‚¬ìš©ì ì •ë³´ ë° ë¶„ì„ ë°ì´í„° ì¶”ê°€
    user_context = f"""

**[ì‚¬ìš©ì ì •ë³´]**
- ì„±ë³„: {user_info['gender']}
- ë‚˜ì´: {user_info['age']}ì„¸
- í•˜ë£¨ ì ìˆ˜: {user_info['emotion_intensity']}/10 (0=ê´œì°®ìŒ, 10=ìµœì•…)"""

    # ë¶„ì„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if 'analysis_data' in st.session_state and st.session_state.analysis_data:
        analysis_data = st.session_state.analysis_data
        analysis_context = f"""

**[ìˆ˜ì§‘ëœ ì •ë³´ - ì°¸ê³ ìš©]**
ì´ì „ ë‹¨ê³„ì—ì„œ ë‹¤ìŒ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤:

â€¢ ê°ì •: {analysis_data.get('emotion', {}).get('primary', 'N/A')}
â€¢ ìë™ì  ì‚¬ê³ : {', '.join(analysis_data.get('logic', {}).get('automatic_thoughts', [])[:2]) if analysis_data.get('logic', {}).get('automatic_thoughts') else 'N/A'}
â€¢ í–‰ë™: {', '.join(analysis_data.get('behavior', {}).get('actions', [])[:2]) if analysis_data.get('behavior', {}).get('actions') else 'N/A'}

ì´ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë” ê¹Šì´ íƒìƒ‰í•˜ì„¸ìš”."""
        
        # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        persona_prompt = get_persona_prompt()
        
        return prompt4 + user_context + analysis_context + persona_prompt
    
    # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    persona_prompt = get_persona_prompt()
    
    return prompt4 + user_context + persona_prompt


def get_system_prompt_evaluator():
    """ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ í‰ê°€ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸"""
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
    prompt_file_path = "prompt2.txt"
    
    # íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt2 = load_prompt_from_file(prompt_file_path)
    
    if not prompt2:
        # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt2 = """ë‹¹ì‹ ì€ ëŒ€í™” ì™„ë£Œ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” í‰ê°€ìì…ë‹ˆë‹¤.
ìƒí™©ê³¼ ê°ì •ì´ ëª¨ë‘ íŒŒì•…ë˜ì—ˆìœ¼ë©´ COMPLETE, ì•„ë‹ˆë©´ INCOMPLETEë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
{
  "status": "COMPLETE" ë˜ëŠ” "INCOMPLETE",
  "reason": "íŒë‹¨ ì´ìœ ",
  "situation_clear": true/false,
  "emotion_expressed": true/false
}"""
    
    return prompt2


def get_system_prompt_extractor():
    """ê°ì •-ë…¼ë¦¬-í–‰ë™ ì¶”ì¶œ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸"""
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
    prompt_file_path = "prompt3.txt"
    
    # íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt3 = load_prompt_from_file(prompt_file_path)
    
    if not prompt3:
        # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt3 = """ë‹¹ì‹ ì€ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê°ì •, ë…¼ë¦¬, í–‰ë™ì„ ì¶”ì¶œí•˜ëŠ” ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "emotion": {"primary": "ì£¼ëœ ê°ì •", "description": "ì„¤ëª…"},
  "logic": {"automatic_thoughts": ["ì‚¬ê³  ë¦¬ìŠ¤íŠ¸"], "description": "ì„¤ëª…"},
  "behavior": {"actions": ["í–‰ë™ ë¦¬ìŠ¤íŠ¸"], "description": "ì„¤ëª…"},
  "summary": "ì „ì²´ ìš”ì•½"
}"""
    
    return prompt3


def get_system_prompt_distortion_evaluator():
    """ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì¤€ë¹„ í‰ê°€ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸"""
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
    prompt_file_path = "prompt5.txt"
    
    # íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt5 = load_prompt_from_file(prompt_file_path)
    
    if not prompt5:
        # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt5 = """ë‹¹ì‹ ì€ ì¸ì§€ì™œê³¡ íƒìƒ‰ ëŒ€í™”ë¥¼ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ 5ê°œ ì˜ì—­ì´ ì¶©ë¶„íˆ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:
1. ìë™ì  ì‚¬ê³ 
2. íŒ¨í„´/ë¹ˆë„
3. ê·¹ë‹¨ì  ì‚¬ê³ 
4. ì¦ê±° ê¸°ë°˜
5. ëŒ€ì•ˆ ê´€ì 

ìµœì†Œ 10í„´ ì´ìƒ, 5ê°œ ì¤‘ 4ê°œ ì´ìƒ ì¶©ì¡± ì‹œ READY
JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
    
    return prompt5


def get_system_prompt_distortion_extractor():
    """ì¸ì§€ì™œê³¡ ìœ í˜• ì¶”ì¶œ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸"""
    # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ
    prompt_file_path = "prompt6.txt"
    
    # íŒŒì¼ì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompt6 = load_prompt_from_file(prompt_file_path)
    
    if not prompt6:
        # íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt6 = """ë‹¹ì‹ ì€ ì²­ì†Œë…„ì˜ ëŒ€í™”ì—ì„œ ì¸ì§€ì™œê³¡ ìœ í˜•ì„ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
7ê°€ì§€ ì™œê³¡ ì¤‘ ê°€ì¥ ë‘ë“œëŸ¬ì§„ 3ê°œë¥¼ ì¶”ì¶œí•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
    
    return prompt6


def get_system_prompt(user_info):
    """í˜„ì¬ ë‹¨ê³„ì— ë§ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
    current_stage = st.session_state.get('current_stage', 'collection')
    
    if current_stage == 'collection':
        return get_system_prompt_stage1(user_info)
    elif current_stage == 'analysis':
        return get_system_prompt_stage2(user_info)
    else:
        # ì¶”í›„ stage3 (restructuring) ì¶”ê°€ ê°€ëŠ¥
        return get_system_prompt_stage1(user_info)


def initialize_chat_messages(user_info):
    """ì±„íŒ… ë©”ì‹œì§€ ì´ˆê¸°í™” (í™˜ì˜ ë©”ì‹œì§€ ì¶”ê°€)"""
    if len(st.session_state.messages) == 0:
        welcome_msg = get_welcome_message(user_info)
        st.session_state.messages.append({
            "role": "assistant",
            "content": welcome_msg
        })


def add_user_message(message):
    """ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€"""
    import datetime
    st.session_state.messages.append({
        "role": "user",
        "content": message,
        "timestamp": datetime.datetime.now().isoformat()
    })


def add_assistant_message(message):
    """ì±—ë´‡ ë©”ì‹œì§€ ì¶”ê°€"""
    import datetime
    st.session_state.messages.append({
        "role": "assistant",
        "content": message,
        "timestamp": datetime.datetime.now().isoformat()
    })


def generate_response_with_gpt(user_message, user_info):
    """GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ í•˜ë“œì½”ë”©)
        api_key = get_api_key()
        
        client = OpenAI(api_key=api_key)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        messages = [
            {"role": "system", "content": get_system_prompt(user_info)}
        ]
        
        # ì´ì „ ëŒ€í™” ë‚´ì—­ ì¶”ê°€ (ìµœê·¼ 10ê°œë§Œ)
        recent_messages = st.session_state.messages[-10:] if len(st.session_state.messages) > 10 else st.session_state.messages
        for msg in recent_messages:
            if msg["role"] in ["user", "assistant"]:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        # GPT API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o",  # ë˜ëŠ” "gpt-3.5-turbo"
            messages=messages,
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"âš ï¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\në¬¸ì œê°€ ê³„ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."


def check_collection_complete_with_evaluator():
    """í‰ê°€ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
    try:
        # API í‚¤
        api_key = get_api_key()
        client = OpenAI(api_key=api_key)
        
        # ëŒ€í™” ë‚´ì—­ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        conversation_text = "ëŒ€í™” ë‚´ìš©:\n"
        for msg in st.session_state.messages:
            role = "ì²­ì†Œë…„" if msg["role"] == "user" else "ìƒë‹´ì‚¬"
            conversation_text += f"{role}: {msg['content']}\n"
        
        # í‰ê°€ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸
        evaluator_prompt = get_system_prompt_evaluator()
        
        # í‰ê°€ ìš”ì²­
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": evaluator_prompt},
                {"role": "user", "content": conversation_text}
            ],
            temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ íŒë‹¨
            max_tokens=200
        )
        
        # ì‘ë‹µ íŒŒì‹±
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        import json
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()
        
        result = json.loads(result_text)
        
        # í‰ê°€ ë¡œê·¸ ì €ì¥
        add_evaluation_log('stage1_evaluation', {
            'status': result.get('status'),
            'collected_areas': result.get('collected_areas', []),
            'missing_areas': result.get('missing_areas', [])
        })
        
        return result.get("status") == "COMPLETE", result
        
    except Exception as e:
        st.error(f"âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë¯¸ì™„ë£Œ ì²˜ë¦¬
        return False, {"status": "INCOMPLETE", "reason": "í‰ê°€ ì˜¤ë¥˜"}


def extract_emotion_logic_behavior():
    """ì¶”ì¶œ ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì •-ë…¼ë¦¬-í–‰ë™ ì¶”ì¶œ"""
    try:
        # API í‚¤
        api_key = get_api_key()
        client = OpenAI(api_key=api_key)
        
        # ëŒ€í™” ë‚´ì—­ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ)
        conversation_text = "ì²­ì†Œë…„ê³¼ì˜ ëŒ€í™” ë‚´ìš©:\n\n"
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                conversation_text += f"ì²­ì†Œë…„: {msg['content']}\n"
        
        # ì¶”ì¶œ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸
        extractor_prompt = get_system_prompt_extractor()
        
        # ì¶”ì¶œ ìš”ì²­
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": extractor_prompt},
                {"role": "user", "content": conversation_text}
            ],
            temperature=0.5,
            max_tokens=800
        )
        
        # ì‘ë‹µ íŒŒì‹±
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹±
        import json
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()
        
        result = json.loads(result_text)
        
        # ì¶”ì¶œ ë¡œê·¸ ì €ì¥
        add_evaluation_log('stage1_extraction', {
            'emotion': result.get('emotion'),
            'logic': result.get('logic'),
            'behavior': result.get('behavior')
        })
        
        return True, result
        
    except Exception as e:
        st.error(f"âš ï¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False, None


def check_distortion_extraction_ready():
    """ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì¤€ë¹„ í‰ê°€"""
    try:
        # API í‚¤
        api_key = get_api_key()
        client = OpenAI(api_key=api_key)
        
        # Stage 2 (analysis) ëŒ€í™”ë§Œ í•„í„°ë§
        analysis_messages = [m for m in st.session_state.messages if m.get('stage') == 'analysis']
        
        # ëŒ€í™” ë‚´ì—­ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        conversation_text = "Stage 2 ì¸ì§€ì™œê³¡ íƒìƒ‰ ëŒ€í™” ë‚´ìš©:\n\n"
        for msg in analysis_messages:
            role = "ì²­ì†Œë…„" if msg["role"] == "user" else "ìƒë‹´ì‚¬"
            conversation_text += f"{role}: {msg['content']}\n"
        
        # í‰ê°€ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸
        evaluator_prompt = get_system_prompt_distortion_evaluator()
        
        # í‰ê°€ ìš”ì²­
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": evaluator_prompt},
                {"role": "user", "content": conversation_text}
            ],
            temperature=0.3,
            max_tokens=500
        )
        
        # ì‘ë‹µ íŒŒì‹±
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹±
        import json
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()
        
        result = json.loads(result_text)
        
        # í‰ê°€ ë¡œê·¸ ì €ì¥
        add_evaluation_log('stage2_evaluation', {
            'status': result.get('status'),
            'collected_areas': result.get('collected_areas', []),
            'missing_info': result.get('missing_info', [])
        })
        
        return result.get("status") == "READY", result
        
    except Exception as e:
        st.error(f"âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë¯¸ì™„ë£Œ ì²˜ë¦¬
        return False, {"status": "NOT_READY", "reason": "í‰ê°€ ì˜¤ë¥˜"}


def extract_cognitive_distortions():
    """ì¸ì§€ì™œê³¡ ìœ í˜• ì¶”ì¶œ ë° í”¼ë“œë°± ìƒì„± (GPT + ë¡œì»¬ ëª¨ë¸ ë³‘í–‰)"""
    try:
        # Stage 2 (analysis) ëŒ€í™”ë§Œ í•„í„°ë§
        analysis_messages = [m for m in st.session_state.messages if m.get('stage') == 'analysis']
        
        # ëŒ€í™” ë‚´ì—­ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        conversation_text = "Stage 2 ëŒ€í™” ë‚´ìš©:\n\n"
        for msg in analysis_messages:
            role = "ì²­ì†Œë…„" if msg["role"] == "user" else "ìƒë‹´ì‚¬"
            conversation_text += f"{role}: {msg['content']}\n"
        
        # 1. GPTë¡œ ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹)
        gpt_success, gpt_result = extract_with_gpt(conversation_text)
        
        # 2. ë¡œì»¬ ëª¨ë¸ë¡œ ì¶”ì¶œ (ìƒˆë¡œìš´ ë°©ì‹)
        local_success, local_result = extract_with_local_model(conversation_text)
        
        # ê²°ê³¼ ë¡œê·¸
        if gpt_success:
            print(f"\n[GPT ì¶”ì¶œ ê²°ê³¼]")
            for dist in gpt_result.get('distortions', []):
                print(f"  - {dist['type']}")
        
        if local_success:
            print(f"\n[ë¡œì»¬ ëª¨ë¸ ì¶”ì¶œ ê²°ê³¼]")
            for dist_type, prob in local_result.items():
                print(f"  - {dist_type}: {prob:.3f}")
        
        # GPT ê²°ê³¼ë¥¼ ìš°ì„  ì‚¬ìš© (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
        if gpt_success:
            return True, gpt_result
        elif local_success:
            # GPT ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ëª¨ë¸ ê²°ê³¼ë¥¼ GPT í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            converted_result = convert_local_to_gpt_format(local_result)
            return True, converted_result
        else:
            return False, None
        
    except Exception as e:
        st.error(f"âš ï¸ ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False, None


def extract_with_gpt(conversation_text):
    """GPTë¥¼ ì‚¬ìš©í•œ ì¸ì§€ì™œê³¡ ì¶”ì¶œ"""
    try:
        # API í‚¤
        api_key = get_api_key()
        client = OpenAI(api_key=api_key)
        
        # ì¶”ì¶œ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸
        extractor_prompt = get_system_prompt_distortion_extractor()
        
        # ì¶”ì¶œ ìš”ì²­
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": extractor_prompt},
                {"role": "user", "content": conversation_text}
            ],
            temperature=0.5,
            max_tokens=1500
        )
        
        # ì‘ë‹µ íŒŒì‹±
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹±
        import json
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()
        
        result = json.loads(result_text)
        
        # ì¶”ì¶œ ë¡œê·¸ ì €ì¥
        add_evaluation_log('distortion_extraction', {
            'method': 'GPT',
            'distortions': [
                {
                    'type': d.get('type'),
                    'type_english': d.get('type_english'),
                    'evidence_count': len(d.get('evidence', []))
                } for d in result.get('distortions', [])
            ]
        })
        
        return True, result
        
    except Exception as e:
        print(f"[GPT ì¶”ì¶œ ì‹¤íŒ¨] {str(e)}")
        return False, None


def extract_with_local_model(conversation_text):
    """ë¡œì»¬ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì¸ì§€ì™œê³¡ ì¶”ì¶œ"""
    try:
        import torch
        from transformers import AutoTokenizer, AutoModelForSequenceClassification
        
        # ëª¨ë¸ ê²½ë¡œ
        MODEL_PATH = r"C:\Users\kma80\Desktop\python_workspace\LLM\ì¤‘ê²¬ì—°êµ¬3\baseline_roberta_large_20250817_052327"
        
        # 10ê°€ì§€ ì¸ì§€ì™œê³¡ ë ˆì´ë¸”
        DISTORTION_LABELS = [
            "í‘ë°± ì‚¬ê³ ",
            "ê³¼ì‰ ì¼ë°˜í™”",
            "ë¶€ì •ì  í¸í–¥",
            "ê¸ì • ì¶•ì†Œí™”",
            "ì„±ê¸‰í•œ íŒë‹¨",
            "í™•ëŒ€ì™€ ì¶•ì†Œ",
            "ê°ì •ì  ì¶”ë¡ ",
            "í•´ì•¼ í•œë‹¤ ì§„ìˆ ",
            "ë‚™ì¸ì°ê¸°",
            "ê°œì¸í™”"
        ]
        
        print(f"\n[ë¡œì»¬ ëª¨ë¸ ë¡œë”© ì‹œì‘...]")
        
        # í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ
        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
        
        # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)
        model.eval()
        
        print(f"[ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ] Device: {device}")
        
        # ëŒ€í™” í…ìŠ¤íŠ¸ë¥¼ í† í°í™”
        inputs = tokenizer(
            conversation_text,
            max_length=512,
            truncation=True,
            padding=True,
            return_tensors="pt"
        )
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        # ì¶”ë¡ 
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.sigmoid(logits)[0]  # Multi-label classification
        
        # í™•ë¥ ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        distortion_probs = {}
        for i, label in enumerate(DISTORTION_LABELS):
            distortion_probs[label] = float(probs[i].cpu().numpy())
        
        # í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_distortions = sorted(
            distortion_probs.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        print(f"\n[ë¡œì»¬ ëª¨ë¸ ì˜ˆì¸¡ í™•ë¥  (ìƒìœ„ 5ê°œ)]")
        for dist_type, prob in sorted_distortions[:5]:
            print(f"  {dist_type}: {prob:.3f}")
        
        return True, distortion_probs
        
    except Exception as e:
        print(f"[ë¡œì»¬ ëª¨ë¸ ì¶”ì¶œ ì‹¤íŒ¨] {str(e)}")
        import traceback
        traceback.print_exc()
        return False, None


def convert_local_to_gpt_format(local_result):
    """ë¡œì»¬ ëª¨ë¸ ê²°ê³¼ë¥¼ GPT í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    # í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 3ê°œ ì„ íƒ
    sorted_distortions = sorted(
        local_result.items(),
        key=lambda x: x[1],
        reverse=True
    )[:3]
    
    # GPT í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    distortions = []
    for dist_type, prob in sorted_distortions:
        distortions.append({
            "type": dist_type,
            "type_english": get_english_name(dist_type),
            "evidence": [],
            "explanation": f"'{dist_type}' íŒ¨í„´ì´ ë³´ì—¬. (í™•ë¥ : {prob:.1%})",
            "pattern": "ì´ëŸ° ìƒê°ì´ ë°˜ë³µë˜ëŠ” ê²ƒ ê°™ì•„."
        })
    
    return {
        "distortions": distortions
    }


def get_english_name(korean_name):
    """í•œê¸€ ì´ë¦„ì„ ì˜ë¬¸ ì´ë¦„ìœ¼ë¡œ ë³€í™˜"""
    mapping = {
        "í‘ë°± ì‚¬ê³ ": "All-or-Nothing Thinking",
        "ê³¼ì‰ ì¼ë°˜í™”": "Overgeneralization",
        "ë¶€ì •ì  í¸í–¥": "Mental Filter",
        "ê¸ì • ì¶•ì†Œí™”": "Disqualifying the Positive",
        "ì„±ê¸‰í•œ íŒë‹¨": "Jumping to Conclusions",
        "í™•ëŒ€ì™€ ì¶•ì†Œ": "Magnification and Minimization",
        "ê°ì •ì  ì¶”ë¡ ": "Emotional Reasoning",
        "í•´ì•¼ í•œë‹¤ ì§„ìˆ ": "Should Statements",
        "ë‚™ì¸ì°ê¸°": "Labeling",
        "ê°œì¸í™”": "Personalization"
    }
    return mapping.get(korean_name, korean_name)


def select_restructuring_method():
    """ì¬êµ¬ì¡°í™” ë°©ë²• ì„ íƒ (í‰ê°€ ì—ì´ì „íŠ¸)"""
    try:
        # API í‚¤
        api_key = get_api_key()
        client = OpenAI(api_key=api_key)
        
        # ì„ íƒëœ ì™œê³¡ ì •ë³´
        selected_distortion = st.session_state.get('selected_distortion', {})
        
        # Stage 1 ë¶„ì„ ë°ì´í„°
        analysis_data = st.session_state.get('analysis_data', {})
        
        # Stage 2 ëŒ€í™”
        analysis_messages = [m for m in st.session_state.messages if m.get('stage') == 'analysis']
        conversation_text = ""
        for msg in analysis_messages:
            role = "ì²­ì†Œë…„" if msg["role"] == "user" else "ìƒë‹´ì‚¬"
            conversation_text += f"{role}: {msg['content']}\n"
        
        # ì…ë ¥ ì •ë³´ êµ¬ì„±
        input_text = f"""ì„ íƒëœ ì¸ì§€ì™œê³¡:
- ìœ í˜•: {selected_distortion.get('type', '')}
- ì˜ë¬¸: {selected_distortion.get('type_english', '')}
- ì¦ê±°: {', '.join(selected_distortion.get('evidence', []))}

ì²­ì†Œë…„ì˜ ìƒí™©:
- Stage 1 ì •ë³´: {analysis_data}

Stage 2 ëŒ€í™”:
{conversation_text}
"""
        
        # í‰ê°€ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸
        evaluator_prompt = get_system_prompt_method_evaluator()
        
        # í‰ê°€ ìš”ì²­
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": evaluator_prompt},
                {"role": "user", "content": input_text}
            ],
            temperature=0.5,
            max_tokens=800
        )
        
        # ì‘ë‹µ íŒŒì‹±
        result_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹±
        import json
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()
        
        result = json.loads(result_text)
        
        # ë°©ë²• ì„ íƒ ë¡œê·¸ ì €ì¥
        add_evaluation_log('restructuring_method_selection', {
            'selected_method': result.get('selected_method'),
            'method_code': result.get('method_code'),
            'reason': result.get('reason'),
            'expected_effectiveness': result.get('expected_effectiveness')
        })
        
        return True, result
        
    except Exception as e:
        print(f"[ì¬êµ¬ì¡°í™” ë°©ë²• ì„ íƒ ì‹¤íŒ¨] {str(e)}")
        return False, None


def get_system_prompt_method_evaluator():
    """ì¬êµ¬ì¡°í™” ë°©ë²• í‰ê°€ ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
    try:
        with open('prompt8.txt', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        return """ë‹¹ì‹ ì€ ì²­ì†Œë…„ì—ê²Œ ê°€ì¥ íš¨ê³¼ì ì¸ ì¸ì§€ ì¬êµ¬ì¡°í™” ë°©ë²•ì„ ì„ íƒí•˜ëŠ” ì „ë¬¸ í‰ê°€ìì…ë‹ˆë‹¤.
5ê°€ì§€ ë°©ë²• ì¤‘ 1ê°œë¥¼ ì„ íƒí•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""


def get_system_prompt_restructuring(user_info):
    """ì¬êµ¬ì¡°í™” ë‹¨ê³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        with open('prompt7.txt', 'r', encoding='utf-8') as f:
            base_prompt = f.read()
    except FileNotFoundError:
        base_prompt = """ë‹¹ì‹ ì€ ì²­ì†Œë…„ì˜ ì¸ì§€ì™œê³¡ì„ ì¬êµ¬ì¡°í™”í•˜ëŠ” ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ê°ì • íƒ€ë‹¹í™”, ì½œë¡¬ë³´ì‹ ì ‘ê·¼, ë…¼ë¦¬ì  ë°˜ë¬¸ì„ ì‚¬ìš©í•˜ì„¸ìš”."""
    
    # ì„ íƒëœ ì¬êµ¬ì¡°í™” ë°©ë²• ì •ë³´
    method_data = st.session_state.get('restructuring_method', {})
    selected_method = method_data.get('selected_method', 'ëŒ€ì•ˆì  ì„¤ëª… ì°¾ê¸°')
    method_code = method_data.get('method_code', 'alternative')
    
    # ì„ íƒëœ ì™œê³¡ ì •ë³´
    selected_distortion = st.session_state.get('selected_distortion', {})
    distortion_type = selected_distortion.get('type', '')
    
    # Stage 1 ë¶„ì„ ì •ë³´
    analysis_data = st.session_state.get('analysis_data', {})
    situation_summary = str(analysis_data)
    
    # í”„ë¡¬í”„íŠ¸ì— ì •ë³´ ì‚½ì…
    base_prompt = base_prompt.replace('{restructuring_method}', selected_method)
    base_prompt = base_prompt.replace('{selected_distortion_type}', distortion_type)
    base_prompt = base_prompt.replace('{situation_summary}', situation_summary)
    
    # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    persona_prompt = get_persona_prompt()
    
    return base_prompt + persona_prompt


def generate_restructuring_response(user_message, user_info):
    """ì¬êµ¬ì¡°í™” ë‹¨ê³„ ì‘ë‹µ ìƒì„±"""
    try:
        # API í‚¤
        api_key = get_api_key()
        client = OpenAI(api_key=api_key)
        
        # ì¬êµ¬ì¡°í™” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = get_system_prompt_restructuring(user_info)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ (Stage 3ë§Œ)
        restructuring_messages = [m for m in st.session_state.messages if m.get('stage') == 'restructuring']
        
        conversation_history = []
        for msg in restructuring_messages:
            conversation_history.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        conversation_history.append({
            "role": "user",
            "content": user_message
        })
        
        # GPT ì‘ë‹µ ìƒì„±
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt}
            ] + conversation_history,
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        print(f"[ì¬êµ¬ì¡°í™” ì‘ë‹µ ìƒì„± ì‹¤íŒ¨] {str(e)}")
        return "ê·¸ ìƒê°ì— ëŒ€í•´ ì¢€ ë” ì•Œë ¤ì¤„ë˜?"


def parse_distortion_selection(user_message):
    """ì‚¬ìš©ìì˜ ì™œê³¡ ì„ íƒ íŒŒì‹± (1, 2, 3)"""
    message = user_message.strip().lower()
    
    # ìˆ«ì ì§ì ‘ ì…ë ¥
    if message in ['1', '2', '3']:
        return int(message)
    
    # "1ë²ˆ", "ì²«ë²ˆì§¸", "ì²« ë²ˆì§¸" ë“±
    if '1' in message or 'ì²«' in message or 'í•˜ë‚˜' in message:
        return 1
    if '2' in message or 'ë‘˜' in message or 'ë‘' in message:
        return 2
    if '3' in message or 'ì…‹' in message or 'ì„¸' in message:
        return 3
    
    return None


def format_distortion_feedback(distortion_data):
    """ì¸ì§€ì™œê³¡ í”¼ë“œë°±ì„ ì§§ê³  ì§ê´€ì ì¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì¦ê±° í¬í•¨)"""
    if not distortion_data or 'distortions' not in distortion_data:
        return "ë„¤ ì´ì•¼ê¸°ë¥¼ ë“¤ìœ¼ë©´ì„œ ëª‡ ê°€ì§€ íŒ¨í„´ì„ ë°œê²¬í–ˆì–´."
    
    feedback = "ë„¤ ì´ì•¼ê¸°ë¥¼ ë“¤ìœ¼ë©´ì„œ ëª‡ ê°€ì§€ íŒ¨í„´ì„ ë°œê²¬í–ˆì–´.\n\n"
    
    # 3ê°€ì§€ ì™œê³¡ì„ ì¦ê±°ì™€ í•¨ê»˜ ì„¤ëª…
    for i, dist in enumerate(distortion_data['distortions'], 1):
        # ë²ˆí˜¸ì™€ ì„¤ëª…
        feedback += f"**{i}. {dist['explanation']}**\n"
        
        # ì¦ê±° ì¶”ê°€ (ìˆìœ¼ë©´)
        if dist.get('evidence') and len(dist['evidence']) > 0:
            feedback += f"   ì˜ˆë¥¼ ë“¤ì–´, "
            # ì¦ê±° 1-2ê°œë§Œ (ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ)
            evidence_list = dist['evidence'][:2]
            if len(evidence_list) == 1:
                feedback += f'"{evidence_list[0]}"ë¼ê³  ë§í–ˆì–ì•„.\n\n'
            else:
                feedback += f'"{evidence_list[0]}", "{evidence_list[1]}" ê°™ì€ ë§ì„ í–ˆì–ì•„.\n\n'
        else:
            feedback += "\n"
    
    return feedback


def format_analysis_result(analysis_data):
    """ì¶”ì¶œëœ ë¶„ì„ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
    if not analysis_data:
        return "ë¶„ì„ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆì–´."
    
    try:
        # summaryê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if "summary" in analysis_data and analysis_data["summary"]:
            return analysis_data["summary"]
        
        # summaryê°€ ì—†ìœ¼ë©´ ì§ì ‘ ìƒì„±
        parts = []
        
        # ê°ì • ë¶€ë¶„
        if "emotion" in analysis_data:
            emotion = analysis_data["emotion"]
            if "primary" in emotion:
                parts.append(f"ë„ˆëŠ” ì£¼ë¡œ {emotion['primary']}ì„(ë¥¼) ëŠê¼ˆì–´.")
        
        # ë…¼ë¦¬ ë¶€ë¶„
        if "logic" in analysis_data:
            logic = analysis_data["logic"]
            if "automatic_thoughts" in logic and logic["automatic_thoughts"]:
                thoughts = "', '".join(logic["automatic_thoughts"][:2])  # ìµœëŒ€ 2ê°œë§Œ
                parts.append(f"'{thoughts}'ë¼ëŠ” ìƒê°ì´ ë“¤ì—ˆê³ .")
        
        # í–‰ë™ ë¶€ë¶„
        if "behavior" in analysis_data:
            behavior = analysis_data["behavior"]
            if "actions" in behavior and behavior["actions"]:
                actions = ", ".join(behavior["actions"][:2])  # ìµœëŒ€ 2ê°œë§Œ
                parts.append(f"{actions}(ì„)ë¥¼ í–ˆêµ¬ë‚˜.")
            elif "avoidance" in behavior and behavior["avoidance"]:
                avoidance = ", ".join(behavior["avoidance"][:2])
                parts.append(f"{avoidance}(ì„)ë¥¼ í•˜ê²Œ ë˜ì—ˆêµ¬ë‚˜.")
        
        return " ".join(parts) if parts else "ë„¤ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì—ˆì–´."
        
    except Exception as e:
        print(f"[í¬ë§·íŒ… ì˜¤ë¥˜] {str(e)}")
        return "ë„¤ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì—ˆì–´."


def process_user_input(user_message, user_info):
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„± - ì•ˆì „ ëª¨ë‹ˆí„°ë§ í†µí•©"""
    
    # ========== ì•ˆì „ ì—ì´ì „íŠ¸ í‰ê°€ ==========
    # ì‘ê¸‰ ëª¨ë“œ ì²´í¬
    if st.session_state.get('emergency_mode', False):
        if SAFETY_AGENT_AVAILABLE:
            display_emergency_screen()
        return
    
    # í˜„ì¬ ë‹¨ê³„ í™•ì¸
    current_stage = st.session_state.get('current_stage', 'collection')
    
    # ì•ˆì „ í‰ê°€ (ë§¤ë²ˆ ì‹¤í–‰!)
    risk_level = 1
    safety_assessment = None
    
    # ë””ë²„ê¹…: ì•ˆì „ ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
    print(f"\n{'='*60}")
    print(f"[ì•ˆì „ ì—ì´ì „íŠ¸ ì²´í¬]")
    print(f"SAFETY_AGENT_AVAILABLE: {SAFETY_AGENT_AVAILABLE}")
    print(f"safety_agent in session: {'safety_agent' in st.session_state}")
    if 'safety_agent' in st.session_state:
        print(f"safety_agent is None: {st.session_state.safety_agent is None}")
    print(f"ì‚¬ìš©ì ë©”ì‹œì§€: {user_message[:50]}...")
    print(f"{'='*60}\n")
    
    if SAFETY_AGENT_AVAILABLE and st.session_state.get('safety_agent'):
        try:
            # ë©”ì‹œì§€ ì¶”ê°€ ì „ì— í‰ê°€
            temp_messages = st.session_state.messages + [{
                "role": "user",
                "content": user_message
            }]
            
            safety_assessment = st.session_state.safety_agent.analyze_risk(
                user_message=user_message,
                conversation_history=temp_messages
            )
            risk_level = safety_assessment.get('risk_level', 1)
            
            print(f"\nğŸ›¡ï¸ [ì•ˆì „ í‰ê°€ ì™„ë£Œ]")
            print(f"Risk Level: {risk_level}")
            print(f"Category: {safety_assessment.get('risk_category', 'NONE')}")
            print(f"Keywords: {safety_assessment.get('detected_keywords', [])}")
            print(f"{'='*60}\n")
            
            # Level 5: ê¸´ê¸‰ - ì¦‰ì‹œ ì¤‘ë‹¨
            if risk_level >= 5:
                add_user_message(user_message)
                st.session_state.messages[-1]['stage'] = current_stage
                
                display_safety_alert(safety_assessment)
                st.session_state.emergency_mode = True
                
                emergency_msg = st.session_state.safety_agent.get_intervention_message(safety_assessment)
                add_assistant_message(emergency_msg)
                st.session_state.messages[-1]['stage'] = current_stage
                st.session_state.messages[-1]['risk_level'] = risk_level
                
                log_safety_assessment(safety_assessment)
                return emergency_msg
            
            # Level 4: ë†’ì€ ìœ„í—˜ - ê²½ê³  í›„ ê³„ì†
            elif risk_level == 4:
                add_user_message(user_message)
                st.session_state.messages[-1]['stage'] = current_stage
                
                display_safety_alert(safety_assessment)
                
                warning_msg = st.session_state.safety_agent.get_intervention_message(safety_assessment)
                add_assistant_message(warning_msg)
                st.session_state.messages[-1]['stage'] = current_stage
                st.session_state.messages[-1]['risk_level'] = risk_level
                
                log_safety_assessment(safety_assessment)
                # ê¸°ì¡´ ì‘ë‹µë„ ê³„ì† ìƒì„± (ì•„ë˜ì—ì„œ)
                
        except Exception as e:
            print(f"âš ï¸ ì•ˆì „ í‰ê°€ ì˜¤ë¥˜: {e}")
            risk_level = 1
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (Level 4, 5ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
    if risk_level < 4:
        add_user_message(user_message)
        st.session_state.messages[-1]['stage'] = current_stage
    
    if current_stage == 'collection':
        # Stage 1: ì •ë³´ ìˆ˜ì§‘ ë‹¨ê³„
        # GPTë¥¼ í†µí•´ ì±—ë´‡ ì‘ë‹µ ìƒì„±
        response = generate_response_with_gpt(user_message, user_info)
        
        # ì±—ë´‡ ì‘ë‹µ ì¶”ê°€
        add_assistant_message(response)
        
        # ===== ì„ íƒì§€ ìƒì„± =====
        if should_provide_options(response, current_stage):
            options = generate_quick_replies(response, user_message, current_stage)
            if options:
                set_quick_replies(options)
            else:
                clear_quick_replies()
        else:
            clear_quick_replies()
        
        # í‰ê°€ ì—ì´ì „íŠ¸ë¡œ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
        # ìµœì†Œ 5í„´(ì‚¬ìš©ì 5ë²ˆ ë©”ì‹œì§€) ì´ìƒì¼ ë•Œë§Œ í‰ê°€
        user_messages = [m for m in st.session_state.messages if m["role"] == "user"]
        if len(user_messages) >= 5:
            is_complete, eval_result = check_collection_complete_with_evaluator()
            
            if is_complete:
                # ì„ íƒì§€ ì´ˆê¸°í™” (ë‹¨ê³„ ì „í™˜ ì‹œ)
                clear_quick_replies()
                
                # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „í™˜
                st.session_state.current_stage = 'analysis'
                
                # í‰ê°€ ì´ìœ ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                if 'reason' in eval_result:
                    print(f"[í‰ê°€ ì™„ë£Œ] {eval_result['reason']}")
                
                # ì¶”ì¶œ ì—ì´ì „íŠ¸ í˜¸ì¶œí•˜ì—¬ ê°ì •-ë…¼ë¦¬-í–‰ë™ ì¶”ì¶œ
                extract_success, analysis_data = extract_emotion_logic_behavior()
                
                if extract_success and analysis_data:
                    # ì¶”ì¶œ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
                    analysis_summary = format_analysis_result(analysis_data)
                    
                    # ì „í™˜ ì•ˆë‚´ ë©”ì‹œì§€ ìƒì„± (ë§ˆì§€ë§‰ ì§ˆë¬¸ ì œê±°, ê³µê° + ì •ë¦¬ + í™•ì¸)
                    transition_msg = f"\n\n---\n\në„¤ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì—ˆì–´. ì§€ê¸ˆê¹Œì§€ ë§í•´ì¤€ ë‚´ìš©ì„ ì •ë¦¬í•´ë³¼ê²Œ.\n\n{analysis_summary}\n\në‚´ê°€ ì´í•´í•œ ê²Œ ë§ì•„?"
                    
                    # ë¶„ì„ ë°ì´í„° ì €ì¥ (ì¶”í›„ í™œìš©)
                    st.session_state.analysis_data = analysis_data
                    
                    print(f"[ë¶„ì„ ì™„ë£Œ] {analysis_summary}")
                else:
                    # ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
                    transition_msg = f"\n\n---\n\në„¤ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì—ˆì–´. ì§€ê¸ˆê¹Œì§€ ë§í•´ì¤€ ë‚´ìš©ì„ ì •ë¦¬í•´ë³¼ê²Œ."
                
                # ë§ˆì§€ë§‰ assistant ë©”ì‹œì§€ë¥¼ ì „í™˜ ë©”ì‹œì§€ë¡œ êµì²´
                st.session_state.messages[-1]["content"] = transition_msg
                response = transition_msg
        
        return response
    
    elif current_stage == 'analysis':
        # Stage 2: ì¸ì§€ì™œê³¡ íƒìƒ‰ ë‹¨ê³„
        
        # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ì§€ í™•ì¸ (ë¶„ì„ ì •ë¦¬ í›„ ì²« ì‘ë‹µ)
        analysis_stage_messages = [m for m in st.session_state.messages if m.get('stage') == 'analysis']
        
        if len(analysis_stage_messages) == 0:
            # ë¶„ì„ ì •ë¦¬ í›„ ì²« ë²ˆì§¸ ì‚¬ìš©ì ì‘ë‹µ ì²˜ë¦¬
            # ê¸ì •/ë¶€ì • ê´€ê³„ì—†ì´ ì¸ì§€ì™œê³¡ íƒìƒ‰ ì‹œì‘
            
            # ê¸ì •ì  ì‘ë‹µ íŒ¨í„´
            positive_patterns = ['ë§', 'ì‘', 'ë„¤', 'ê·¸ë˜', 'ì˜ˆ', 'ê·¸ë ‡', 'ë§ì•„', 'ì˜¤ì¼€ì´', 'ã…‡ã…‡', 'ã…‡ã…‹']
            is_positive = any(pattern in user_message.lower() for pattern in positive_patterns)
            
            if is_positive:
                intro_msg = "ê·¸ë˜, ìš°ë¦¬ ì¢€ ë” ê¹Šì´ ì•Œì•„ê°€ë³¼ê¹Œ?"
            else:
                intro_msg = "ê·¸ëŸ¼ ë” ìì„¸íˆ ì´ì•¼ê¸°í•´ë³´ì."
            
            # ë„ì… ë©”ì‹œì§€ ì¶”ê°€
            add_assistant_message(intro_msg)
            
            # íƒìƒ‰ ì‹œì‘ ë©”ì‹œì§€ ìƒì„±
            response = generate_response_with_gpt(f"{intro_msg}\n\n{user_message}", user_info)
            add_assistant_message(response)
            
            # stage íƒœê·¸ ì¶”ê°€ (ì¶”ì ìš©)
            st.session_state.messages[-2]['stage'] = 'analysis'
            st.session_state.messages[-1]['stage'] = 'analysis'
            
            return intro_msg + "\n\n" + response
        else:
            # ì¬êµ¬ì¡°í™” ì‹œì‘ ëŒ€ê¸° ì¤‘ì¸ì§€ í™•ì¸
            if st.session_state.get('awaiting_restructuring_start', False):
                # ê¸ì •ì  ì‘ë‹µ íŒ¨í„´
                positive_patterns = ['ì¢‹', 'ì‘', 'ë„¤', 'ê·¸ë˜', 'ì˜ˆ', 'ì˜¤ì¼€ì´', 'ã…‡ã…‡', 'ã…‡ã…‹', 'ì•Œê² ', 'í•´ë³´']
                is_positive = any(pattern in user_message.lower() for pattern in positive_patterns)
                
                if is_positive:
                    # Stage 3ë¡œ ì „í™˜
                    st.session_state.current_stage = 'restructuring'
                    st.session_state.awaiting_restructuring_start = False
                    
                    print(f"\n{'='*60}")
                    print(f"[Stage 3: ì¸ì§€ ì¬êµ¬ì¡°í™” ì‹œì‘]")
                    print(f"{'='*60}\n")
                    
                    # ì¬êµ¬ì¡°í™” ë°©ë²• ì„ íƒ (í‰ê°€ ì—ì´ì „íŠ¸)
                    method_success, method_data = select_restructuring_method()
                    
                    if method_success and method_data:
                        st.session_state.restructuring_method = method_data
                        
                        print(f"[ì„ íƒëœ ì¬êµ¬ì¡°í™” ë°©ë²•: {method_data['selected_method']}]")
                        print(f"[ì„ íƒ ì´ìœ : {method_data['reason']}]")
                        
                        # ì¬êµ¬ì¡°í™” ì²« ì§ˆë¬¸ ìƒì„±
                        first_question = generate_restructuring_response(user_message, user_info)
                        add_assistant_message(first_question)
                        st.session_state.messages[-1]['stage'] = 'restructuring'
                        
                        return first_question
                    else:
                        # ë°©ë²• ì„ íƒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì¬êµ¬ì¡°í™”
                        st.session_state.current_stage = 'restructuring'
                        first_question = "ê·¸ëŸ¼ ì´ íŒ¨í„´ì— ëŒ€í•´ ê°™ì´ ìƒê°í•´ë³¼ê¹Œ? ë„¤ê°€ ì´ë ‡ê²Œ ìƒê°í•˜ê²Œ ëœ ì´ìœ ê°€ ë­˜ê¹Œ?"
                        add_assistant_message(first_question)
                        st.session_state.messages[-1]['stage'] = 'restructuring'
                        return first_question
                else:
                    # ë¶€ì •ì  ì‘ë‹µ
                    return_msg = "ê´œì°®ì•„. ì²œì²œíˆ ìƒê°í•´ë´ë„ ë¼. ì¤€ë¹„ë˜ë©´ ë§í•´ì¤˜."
                    add_assistant_message(return_msg)
                    st.session_state.messages[-1]['stage'] = 'analysis'
                    return return_msg
            
            # ì¸ì§€ì™œê³¡ ì„ íƒ ëŒ€ê¸° ì¤‘ì¸ì§€ í™•ì¸
            if st.session_state.get('awaiting_distortion_selection', False):
                # ì‚¬ìš©ìì˜ ì„ íƒ ì²˜ë¦¬
                selection = parse_distortion_selection(user_message)
                
                if selection is not None:
                    # ì„ íƒëœ ì™œê³¡ ì €ì¥
                    distortion_data = st.session_state.get('distortion_data', {})
                    if distortion_data and 'distortions' in distortion_data:
                        selected = distortion_data['distortions'][selection - 1]
                        st.session_state.selected_distortion = selected
                        st.session_state.awaiting_distortion_selection = False
                        
                        print(f"\n{'='*60}")
                        print(f"[ì²­ì†Œë…„ì´ ì„ íƒí•œ ì™œê³¡: {selected['type']}]")
                        print(f"{'='*60}\n")
                        
                        # ì„ íƒ í™•ì¸ ë©”ì‹œì§€
                        confirmation = f"ê·¸ë˜, '{selected['type']}'ê°€ ì œì¼ í¬ê²Œ ë‹¤ê°€ì˜¤ëŠ”êµ¬ë‚˜. ì´ íŒ¨í„´ì— ëŒ€í•´ ì¢€ ë” ì´ì•¼ê¸°í•´ë³¼ê¹Œ?"
                        add_assistant_message(confirmation)
                        st.session_state.messages[-1]['stage'] = 'analysis'
                        
                        # Stage 3 ì „í™˜ ëŒ€ê¸°
                        st.session_state.awaiting_restructuring_start = True
                        
                        return confirmation
                else:
                    # ì˜ëª»ëœ ì…ë ¥
                    retry_msg = "1, 2, 3 ì¤‘ì— í•˜ë‚˜ë¥¼ ì„ íƒí•´ì¤˜. ì–´ë–¤ íŒ¨í„´ì´ ì œì¼ í¬ê²Œ ë‹¤ê°€ì™€?"
                    add_assistant_message(retry_msg)
                    st.session_state.messages[-1]['stage'] = 'analysis'
                    return retry_msg
            
            # ì´í›„ ì¸ì§€ì™œê³¡ íƒìƒ‰ ëŒ€í™” ê³„ì†
            response = generate_response_with_gpt(user_message, user_info)
            add_assistant_message(response)
            st.session_state.messages[-1]['stage'] = 'analysis'
            
            # ===== ì„ íƒì§€ ìƒì„± =====
            if should_provide_options(response, current_stage):
                options = generate_quick_replies(response, user_message, current_stage)
                if options:
                    set_quick_replies(options)
                else:
                    clear_quick_replies()
            else:
                clear_quick_replies()
            
            # ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì¤€ë¹„ í‰ê°€ (ìµœì†Œ 5í„´ ì´ìƒì¼ ë•Œ)
            # ì´ë¯¸ ì¶”ì¶œì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ê³„ì† í‰ê°€
            if not st.session_state.get('distortion_extracted', False):
                analysis_user_messages = [m for m in st.session_state.messages 
                                         if m["role"] == "user" and m.get('stage') == 'analysis']
                
                current_turn = len(analysis_user_messages)
                print(f"\n{'='*60}")
                print(f"[Stage 2 - í„´ {current_turn}] í‰ê°€ ì‹œì‘")
                print(f"{'='*60}")
                
                if len(analysis_user_messages) >= 5:
                    print(f"[í„´ ìˆ˜ í™•ì¸] âœ… {current_turn}í„´ (5í„´ ì´ìƒ - í‰ê°€ ì§„í–‰)")
                    
                    is_ready, eval_result = check_distortion_extraction_ready()
                    
                    # í‰ê°€ ê²°ê³¼ ìƒì„¸ ì¶œë ¥
                    print(f"\n[í‰ê°€ ê²°ê³¼]")
                    print(f"  - ìƒíƒœ: {eval_result.get('status')}")
                    print(f"  - ì´ìœ : {eval_result.get('reason', 'N/A')}")
                    print(f"  - ìˆ˜ì§‘ ì˜ì—­: {eval_result.get('coverage', 'N/A')}")
                    
                    if 'collected_areas' in eval_result:
                        print(f"\n[ì˜ì—­ë³„ ìˆ˜ì§‘ í˜„í™©]")
                        for area, collected in eval_result['collected_areas'].items():
                            status = "âœ…" if collected else "âŒ"
                            print(f"  {status} {area}")
                    
                    if is_ready:
                        print(f"\n{'ğŸ‰'*20}")
                        print(f"[ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì¤€ë¹„ ì™„ë£Œ!]")
                        print(f"{'ğŸ‰'*20}")
                        
                        # ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì—ì´ì „íŠ¸ í˜¸ì¶œ
                        print(f"\n[ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì‹œì‘...]")
                        extract_success, distortion_data = extract_cognitive_distortions()
                        
                        if extract_success and distortion_data:
                            print(f"\n[ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì„±ê³µ!]")
                            print(f"  - ì¶”ì¶œëœ ì™œê³¡ ê°œìˆ˜: {len(distortion_data['distortions'])}ê°œ")
                            
                            for i, dist in enumerate(distortion_data['distortions'], 1):
                                print(f"\n  {i}. {dist['type']} ({dist['type_english']})")
                                print(f"     ì¦ê±°: {dist['evidence'][0][:50]}..." if dist['evidence'] else "     ì¦ê±°: ì—†ìŒ")
                            
                            # ì¸ì§€ì™œê³¡ í”¼ë“œë°± ìƒì„±
                            distortion_feedback = format_distortion_feedback(distortion_data)
                            
                            # ì„ íƒ ì§ˆë¬¸ ì¶”ê°€
                            selection_question = "\nì´ ì¤‘ì—ì„œ ì–´ë–¤ ê²Œ ì œì¼ ë„ˆì˜ ìƒí™©ì— í¬ê²Œ ë‹¤ê°€ì˜¤ëŠ” ê²ƒ ê°™ì•„? 1, 2, 3 ì¤‘ì— ê³¨ë¼ë´."
                            
                            # ê¸°ì¡´ ì‘ë‹µ(ì§ˆë¬¸)ì„ ì œê±°í•˜ê³  í”¼ë“œë°±ìœ¼ë¡œ êµì²´
                            st.session_state.messages[-1]['content'] = distortion_feedback + selection_question
                            
                            # ì¸ì§€ì™œê³¡ ë°ì´í„° ì €ì¥ (ì¶”í›„ í™œìš©)
                            st.session_state.distortion_data = distortion_data
                            st.session_state.distortion_extracted = True  # ì¶”ì¶œ ì™„ë£Œ í”Œë˜ê·¸
                            st.session_state.awaiting_distortion_selection = True  # ì„ íƒ ëŒ€ê¸° ì¤‘
                            
                            print(f"\n[í”¼ë“œë°± ì „ë‹¬ ì™„ë£Œ]")
                            print(f"[ì²­ì†Œë…„ ì„ íƒ ëŒ€ê¸° ì¤‘...]")
                            print(f"{'='*60}\n")
                            
                            # Stage ì™„ë£Œ - ì¶”í›„ Stage 3ë¡œ ì „í™˜ ê°€ëŠ¥
                            # st.session_state.current_stage = 'next_stage'
                            
                            return distortion_feedback + selection_question  # í”¼ë“œë°± + ì„ íƒ ì§ˆë¬¸ ë°˜í™˜
                        else:
                            print(f"\n[âš ï¸ ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì‹¤íŒ¨]")
                            st.info("âœ… ì¸ì§€ì™œê³¡ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        print(f"\n[ì•„ì§ ì¤€ë¹„ ì•ˆ ë¨]")
                        if 'missing_info' in eval_result and eval_result['missing_info']:
                            print(f"  ë¶€ì¡±í•œ ì •ë³´:")
                            for info in eval_result['missing_info']:
                                print(f"    - {info}")
                        
                        if 'next_questions' in eval_result and eval_result['next_questions']:
                            print(f"  ì¶”ì²œ ì§ˆë¬¸:")
                            for q in eval_result['next_questions'][:3]:
                                print(f"    - {q}")
                    
                    print(f"{'='*60}\n")
                else:
                    print(f"[í„´ ìˆ˜ í™•ì¸] â³ {current_turn}í„´ (5í„´ ë¯¸ë§Œ - í‰ê°€ ëŒ€ê¸° ì¤‘)")
                    print(f"  â†’ {5 - current_turn}í„´ ë” í•„ìš”")
                    print(f"{'='*60}\n")
            else:
                print(f"\n[ì¸ì§€ì™œê³¡ ì¶”ì¶œ ì™„ë£Œë¨] ì´ë¯¸ í”¼ë“œë°±ì„ ì „ë‹¬í–ˆìŠµë‹ˆë‹¤.\n")
            
            return response
    
    elif current_stage == 'restructuring':
        # Stage 3: ì¸ì§€ ì¬êµ¬ì¡°í™” ë‹¨ê³„
        
        # ì¬êµ¬ì¡°í™” ì‘ë‹µ ìƒì„±
        response = generate_restructuring_response(user_message, user_info)
        add_assistant_message(response)
        st.session_state.messages[-1]['stage'] = 'restructuring'
        
        return response
    
    else:
        # ê¸°íƒ€ ë‹¨ê³„ëŠ” ì¶”í›„ êµ¬í˜„
        response = generate_response_with_gpt(user_message, user_info)
        add_assistant_message(response)
        return response


# ========== ë¹ ë¥¸ ë‹µë³€ ì„ íƒì§€ ìƒì„± ==========

def should_provide_options(response, current_stage):
    """
    ì„ íƒì§€ ì œê³µ ì—¬ë¶€ íŒë‹¨
    
    Args:
        response: AI ì‘ë‹µ í…ìŠ¤íŠ¸
        current_stage: í˜„ì¬ ë‹¨ê³„ (collection, analysis, restructuring)
    
    Returns:
        bool: ì„ íƒì§€ ì œê³µ ì—¬ë¶€
    """
    # Stage 3 (ì¬êµ¬ì¡°í™”)ì—ì„œëŠ” ì„ íƒì§€ ì œê³µ ì•ˆ í•¨
    if current_stage == 'restructuring':
        return False
    
    # Stage 1, 2ì—ì„œë§Œ ì œê³µ
    if current_stage not in ['collection', 'analysis']:
        return False
    
    # ì§ˆë¬¸ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
    if response.strip().endswith('?') or '?' in response[-30:]:
        return True
    
    # íŠ¹ì • í‚¤ì›Œë“œ í¬í•¨ ì‹œ
    question_keywords = ['ì–´ë–»ê²Œ', 'ë­ê°€', 'ì–¸ì œ', 'ì™œ', 'ì–´ë• ', 'ëŠê¼ˆ', 'ìƒê°', 'ì–´ë–¤']
    if any(keyword in response for keyword in question_keywords):
        return True
    
    return False


def generate_quick_replies(response, user_message, current_stage):
    """
    GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥¸ ë‹µë³€ ì„ íƒì§€ ìƒì„±
    
    Args:
        response: AI ì‘ë‹µ
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        current_stage: í˜„ì¬ ë‹¨ê³„
    
    Returns:
        list: 2-4ê°œì˜ ì„ íƒì§€ (ë˜ëŠ” None)
    """
    try:
        api_key = get_api_key()
        if not api_key:
            return None
        
        client = OpenAI(api_key=api_key)
        
        # ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì¡°ì •
        if current_stage == 'collection':
            context_hint = "Stage 1 (ì •ë³´ ìˆ˜ì§‘): ìƒí™©, ê°ì •, í–‰ë™ì„ íŒŒì•…í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤."
        elif current_stage == 'analysis':
            context_hint = "Stage 2 (ì¸ì§€ì™œê³¡ íƒìƒ‰): ìë™ì  ì‚¬ê³ , íŒ¨í„´, ê·¹ë‹¨ì„±ì„ íŒŒì•…í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤."
        else:
            context_hint = ""
        
        # ì„ íƒì§€ ìƒì„± í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒ AI ì‘ë‹µì— ëŒ€í•´ ì²­ì†Œë…„ì´ **ì„ íƒí•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ë‹µë³€ ì„ íƒì§€ 3ê°œ**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

{context_hint}

[AI ì‘ë‹µ]
{response}

[ì´ì „ ì‚¬ìš©ì ë©”ì‹œì§€]
{user_message}

**ì„ íƒì§€ ìƒì„± ê·œì¹™:**
1. ê° ì„ íƒì§€ëŠ” **8ì ì´ë‚´**ë¡œ ì§§ê²Œ
2. ì²­ì†Œë…„ì´ ì‰½ê²Œ ì„ íƒí•  ìˆ˜ ìˆë„ë¡
3. ë‹¤ì–‘í•œ ë°©í–¥ì˜ ë‹µë³€ í¬í•¨ (ê¸ì •ì /ë¶€ì •ì /ì¤‘ë¦½ì )
4. ìì—°ìŠ¤ëŸ½ê³  êµ¬ì–´ì²´ë¡œ
5. ë§ˆì§€ë§‰ ì„ íƒì§€ëŠ” ë°˜ë“œì‹œ "ì§ì ‘ ì…ë ¥í• ê²Œ"

**JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:**
{{
  "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì§ì ‘ ì…ë ¥í• ê²Œ"]
}}
"""
        
        response_obj = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì²­ì†Œë…„ ì¹œí™”ì ì¸ ì§§ì€ ì„ íƒì§€ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=200,
            response_format={"type": "json_object"}
        )
        
        result_text = response_obj.choices[0].message.content
        result = json.loads(result_text)
        options = result.get('options', [])
        
        # ì„ íƒì§€ ê²€ì¦
        if len(options) == 3:
            # ê° ì„ íƒì§€ ê¸¸ì´ ì²´í¬ (10ì ì´í•˜)
            if all(len(opt) <= 10 for opt in options):
                print(f"[ì„ íƒì§€ ìƒì„± ì„±ê³µ] {options}")
                return options
        
        print(f"[ì„ íƒì§€ ìƒì„± ì‹¤íŒ¨] ì¡°ê±´ ë¶ˆë§Œì¡±: {options}")
        return None
        
    except Exception as e:
        print(f"[ì„ íƒì§€ ìƒì„± ì˜¤ë¥˜] {str(e)}")
        return None


def set_quick_replies(options):
    """ì„ íƒì§€ë¥¼ ì„¸ì…˜ì— ì €ì¥"""
    st.session_state.quick_replies = options


def clear_quick_replies():
    """ì„ íƒì§€ ì´ˆê¸°í™”"""
    st.session_state.quick_replies = None
